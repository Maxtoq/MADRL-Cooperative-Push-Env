{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f69e29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390e5bd",
   "metadata": {},
   "source": [
    "## Load language data\n",
    "\n",
    "Load sentences from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "362fa761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Located', 'South'],\n",
       " ['Located', 'Center', 'Object', 'East'],\n",
       " ['Located', 'South'],\n",
       " ['Located', 'East', 'Object', 'South', 'East'],\n",
       " ['Located', 'South']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"sentences.json\") as f:\n",
    "    sentences = json.load(f)\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c2184",
   "metadata": {},
   "source": [
    "Add start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a1d646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<SOS>', 'Located', 'South', '<EOS>'],\n",
       " ['<SOS>', 'Located', 'Center', 'Object', 'East', '<EOS>'],\n",
       " ['<SOS>', 'Located', 'South', '<EOS>'],\n",
       " ['<SOS>', 'Located', 'East', 'Object', 'South', 'East', '<EOS>'],\n",
       " ['<SOS>', 'Located', 'South', '<EOS>']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [[\"<SOS>\"] + s + [\"<EOS>\"] for s in sentences]\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c7d59",
   "metadata": {},
   "source": [
    "Get vocabulary and one-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff0b5d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>',\n",
       " 'South',\n",
       " 'Not',\n",
       " 'Located',\n",
       " 'West',\n",
       " '<EOS>',\n",
       " 'Object',\n",
       " 'Landmark',\n",
       " 'North',\n",
       " 'Center',\n",
       " 'East']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_voc(sentence_list):\n",
    "    words = []\n",
    "    for s in sentences:\n",
    "        words.extend(s)\n",
    "    vocab = list(set(words))\n",
    "    return vocab\n",
    "vocab = get_voc(sentences)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9901a7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<SOS>': array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'South': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'Not': array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'Located': array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'West': array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " '<EOS>': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 'Object': array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 'Landmark': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " 'North': array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 'Center': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 'East': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_onehots(vocab):\n",
    "    dim_vocab = len(vocab)\n",
    "    word_encodings = {}\n",
    "    for i, w in enumerate(vocab):\n",
    "        word_encodings[w] = np.eye(dim_vocab)[i]\n",
    "    return word_encodings\n",
    "word_encodings = get_word_onehots(vocab)\n",
    "word_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659354c",
   "metadata": {},
   "source": [
    "## Language modelling\n",
    "\n",
    "Encode a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c25785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence):\n",
    "    encoded = []\n",
    "    for token in sentence:\n",
    "        encoded.append(word_encodings[token])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27ed561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sentences[0]\n",
    "enc = torch.Tensor(np.array(encode(s)))\n",
    "enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba5023",
   "metadata": {},
   "source": [
    "Pass through a GRU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7c57abc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 256])\n",
      "tensor([[[-0.0273, -0.0381,  0.0491,  ...,  0.0233, -0.0184, -0.0060],\n",
      "         [-0.0307, -0.0049,  0.0814,  ...,  0.0138, -0.0240, -0.0258],\n",
      "         [-0.0426, -0.0411,  0.0853,  ...,  0.0386, -0.0494, -0.0713],\n",
      "         [-0.0202, -0.0136,  0.0417,  ...,  0.0524, -0.0694, -0.0537]]],\n",
      "       grad_fn=<TransposeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(len(vocab), 256, batch_first=True)\n",
    "output, hidden_state = gru(enc.unsqueeze(0))\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f63beabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256])\n",
      "tensor([[[-0.0245,  0.0025,  0.0407, -0.0674,  0.0386, -0.0226, -0.0477,\n",
      "          -0.0623,  0.0702,  0.0445, -0.0867,  0.0543, -0.0297,  0.0321,\n",
      "          -0.0051, -0.0245,  0.0194, -0.0044,  0.0009, -0.0593, -0.0498,\n",
      "           0.0541,  0.0269,  0.0424,  0.0513, -0.0041,  0.0003, -0.0171,\n",
      "           0.0191, -0.0561,  0.0725,  0.0132,  0.0229,  0.0225,  0.0101,\n",
      "           0.0582,  0.0647,  0.0334,  0.0280,  0.0413, -0.0410,  0.0005,\n",
      "          -0.0022,  0.0095, -0.0815,  0.0039,  0.0253, -0.0003,  0.0613,\n",
      "           0.0340, -0.0445,  0.0419,  0.0109, -0.0446, -0.0284,  0.0326,\n",
      "          -0.0544, -0.0198, -0.0541,  0.0600,  0.0132,  0.0467, -0.0732,\n",
      "           0.0313,  0.0161, -0.0561, -0.0723, -0.0614, -0.0824, -0.0747,\n",
      "           0.0415,  0.0353,  0.0226, -0.0059, -0.0896, -0.0031,  0.0057,\n",
      "          -0.0100, -0.0263,  0.0264,  0.0641, -0.0525,  0.0349,  0.0260,\n",
      "           0.0502,  0.0830, -0.0153,  0.0977, -0.0269, -0.0787, -0.0678,\n",
      "           0.0818,  0.0977,  0.0393, -0.0028,  0.0103, -0.0519,  0.0050,\n",
      "           0.0343,  0.0300,  0.0677,  0.0152, -0.0641,  0.0302, -0.0555,\n",
      "          -0.0590, -0.0044,  0.0252,  0.0496,  0.0114, -0.0559, -0.0987,\n",
      "           0.0089,  0.0584, -0.0623, -0.0334, -0.0078,  0.0569,  0.0069,\n",
      "          -0.0194, -0.0235,  0.0390, -0.0365, -0.0342, -0.0336, -0.0239,\n",
      "          -0.0132, -0.0327, -0.0525,  0.0425, -0.0509, -0.0043,  0.0331,\n",
      "          -0.0422, -0.0343, -0.0115, -0.0304, -0.0387, -0.0487, -0.0594,\n",
      "           0.0595,  0.0436,  0.0019,  0.0909, -0.0251,  0.0695,  0.0270,\n",
      "           0.0068,  0.0338,  0.0227, -0.0272,  0.0105,  0.0161, -0.0536,\n",
      "           0.0283,  0.0841,  0.0598, -0.0353,  0.0147, -0.0722, -0.1025,\n",
      "           0.0667,  0.0013, -0.0181,  0.0797,  0.0463, -0.0290,  0.0423,\n",
      "          -0.0455,  0.0049, -0.0268,  0.0708, -0.0612,  0.0319, -0.0359,\n",
      "          -0.0215,  0.0593, -0.0541, -0.0394,  0.0327,  0.0620, -0.0524,\n",
      "          -0.0318, -0.0122,  0.0451, -0.0722, -0.0210, -0.0487, -0.0093,\n",
      "          -0.0162, -0.0707, -0.0084, -0.0174, -0.0394, -0.0157, -0.0354,\n",
      "           0.0492, -0.0234, -0.0052, -0.0418, -0.0786, -0.0248, -0.0733,\n",
      "          -0.0843,  0.0428, -0.0404,  0.0159, -0.0054, -0.0868,  0.0218,\n",
      "           0.0548,  0.0504, -0.0247,  0.0501,  0.0223,  0.0017, -0.0562,\n",
      "          -0.0068,  0.0298,  0.0476, -0.0275, -0.0092,  0.0007,  0.0124,\n",
      "           0.0180, -0.0448,  0.0356, -0.0099, -0.0170,  0.0791, -0.0111,\n",
      "          -0.0564, -0.0016,  0.0446,  0.0853, -0.0184,  0.0022,  0.0207,\n",
      "          -0.0351, -0.0391,  0.0514, -0.0407,  0.0533,  0.0186, -0.0574,\n",
      "           0.0369, -0.0116, -0.0521, -0.0980, -0.0290, -0.0382,  0.0523,\n",
      "           0.0072, -0.0152, -0.0447, -0.0546]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hidden_state.shape)\n",
    "print(hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e3ce5f",
   "metadata": {},
   "source": [
    "Padding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e95eef12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "[1, 2, 0]\n",
      "[tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])]\n",
      "False\n",
      "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
      "[7, 6, 4]\n",
      "PackedSequence(data=tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "PackedSequence(data=tensor([[-0.0132,  0.0071, -0.0134,  ..., -0.0478,  0.0023, -0.0512],\n",
      "        [-0.0132,  0.0071, -0.0134,  ..., -0.0478,  0.0023, -0.0512],\n",
      "        [-0.0132,  0.0071, -0.0134,  ..., -0.0478,  0.0023, -0.0512],\n",
      "        ...,\n",
      "        [-0.0550,  0.0271, -0.0729,  ..., -0.0740,  0.0332, -0.0337],\n",
      "        [-0.0537,  0.0325, -0.0483,  ..., -0.0793,  0.0254, -0.0211],\n",
      "        [-0.0521,  0.0437, -0.0446,  ..., -0.0833,  0.0312, -0.0210]],\n",
      "       grad_fn=<CatBackward0>), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "tensor([[[-0.0132,  0.0071, -0.0134,  ..., -0.0478,  0.0023, -0.0512],\n",
      "         [-0.0383,  0.0102, -0.0224,  ..., -0.0878,  0.0355, -0.0616],\n",
      "         [-0.0350,  0.0235, -0.0593,  ..., -0.0718,  0.0269, -0.0545],\n",
      "         ...,\n",
      "         [-0.0757,  0.0166, -0.0387,  ..., -0.0816,  0.0473, -0.0321],\n",
      "         [-0.0550,  0.0271, -0.0729,  ..., -0.0740,  0.0332, -0.0337],\n",
      "         [-0.0521,  0.0437, -0.0446,  ..., -0.0833,  0.0312, -0.0210]],\n",
      "\n",
      "        [[-0.0132,  0.0071, -0.0134,  ..., -0.0478,  0.0023, -0.0512],\n",
      "         [-0.0383,  0.0102, -0.0224,  ..., -0.0878,  0.0355, -0.0616],\n",
      "         [-0.0794, -0.0231, -0.0623,  ..., -0.0667,  0.0320, -0.0451],\n",
      "         ...,\n",
      "         [-0.0601,  0.0047, -0.0813,  ..., -0.0663,  0.0229, -0.0332],\n",
      "         [-0.0537,  0.0325, -0.0483,  ..., -0.0793,  0.0254, -0.0211],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0132,  0.0071, -0.0134,  ..., -0.0478,  0.0023, -0.0512],\n",
      "         [-0.0383,  0.0102, -0.0224,  ..., -0.0878,  0.0355, -0.0616],\n",
      "         [-0.0574,  0.0244, -0.0146,  ..., -0.0886,  0.0525, -0.0483],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(np.array(encode(sentences[0])))\n",
    "b = torch.Tensor(np.array(encode(sentences[3])))\n",
    "c = torch.Tensor(np.array(encode(sentences[1])))\n",
    "sentence_list = [a, b, c]\n",
    "print(sentence_list)\n",
    "\n",
    "gru = nn.GRU(len(vocab), 256, batch_first=True)\n",
    "\n",
    "# Order\n",
    "ids = sorted(range(len(sentence_list)), key=lambda x: len(sentence_list[x]), reverse=True)\n",
    "print(ids)\n",
    "\n",
    "# Sort by length of sentence\n",
    "sentence_list.sort(key=len, reverse=True)\n",
    "print(sentence_list)\n",
    "\n",
    "# Pad sentences\n",
    "padded = nn.utils.rnn.pad_sequence(sentence_list, batch_first=True)\n",
    "print(padded.requires_grad)\n",
    "print(padded)\n",
    "\n",
    "# Pack padded sentences (to not take care of padded tokens)\n",
    "lens = [len(s) for s in sentence_list]\n",
    "print(lens)\n",
    "packed = nn.utils.rnn.pack_padded_sequence(padded, lens, batch_first=True)\n",
    "print(packed)\n",
    "\n",
    "output, hidden_state = gru(packed)\n",
    "print(output)\n",
    "\n",
    "# Re-pad sequence of embeddings\n",
    "output, sizes = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e19902b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.retain_grad()\n",
    "e.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dff1c3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.6147e-09, -9.0695e-07,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          6.1077e-09, -1.1247e-06],\n",
      "        [ 4.3696e-07,  2.5419e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          4.2694e-07,  2.4686e-06],\n",
      "        [-8.5177e-07, -4.5599e-06,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -8.2568e-07, -8.3661e-06],\n",
      "        ...,\n",
      "        [ 9.6453e-05,  4.1863e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          6.5748e-05,  5.8530e-04],\n",
      "        [ 2.8425e-04,  7.3727e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.8478e-04,  9.9559e-04],\n",
      "        [ 1.3736e-04,  5.1098e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          9.3814e-05,  7.2468e-04]])\n",
      "tensor([[ 2.9201e-08,  2.3870e-07,  5.6055e-09,  ..., -6.5194e-08,\n",
      "         -2.0833e-07,  2.0006e-07],\n",
      "        [-9.2575e-08, -7.8011e-07, -3.9043e-08,  ...,  1.7219e-07,\n",
      "          6.9074e-07, -6.5954e-07],\n",
      "        [ 2.3542e-07,  1.6923e-06, -8.9774e-08,  ..., -5.8697e-07,\n",
      "         -1.2204e-06,  1.0124e-06],\n",
      "        ...,\n",
      "        [-1.3274e-05, -8.1712e-05,  8.6187e-07,  ...,  2.3205e-05,\n",
      "          6.0663e-05, -5.1140e-05],\n",
      "        [-1.0367e-05, -1.0327e-04,  6.3588e-06,  ...,  3.2093e-05,\n",
      "          8.3777e-05, -6.8416e-05],\n",
      "        [-1.1035e-05, -8.3480e-05,  3.1000e-06,  ...,  2.5595e-05,\n",
      "          6.4265e-05, -5.3685e-05]])\n",
      "tensor([-4.7002e-06,  1.6295e-05, -3.7418e-05, -4.1267e-05,  5.6760e-05,\n",
      "         8.5028e-06, -6.0175e-05, -4.8426e-05, -3.1590e-05,  4.8215e-05,\n",
      "         6.1081e-05, -4.5411e-05,  7.4177e-06, -1.4473e-05,  6.0757e-06,\n",
      "        -3.8177e-05, -5.3071e-05,  2.1001e-05, -5.5036e-05, -4.4694e-05,\n",
      "         2.4267e-05,  6.5968e-05, -4.7590e-05, -2.5787e-05, -2.4033e-06,\n",
      "         4.3265e-05,  3.4744e-05, -5.8699e-07, -2.9379e-05,  1.2996e-05,\n",
      "         1.6895e-05,  7.3424e-06,  5.2332e-05, -2.9058e-05, -1.3331e-05,\n",
      "         2.5030e-05,  4.6784e-05, -1.2505e-05, -4.3530e-05, -7.1356e-05,\n",
      "         4.8852e-06, -6.4670e-05, -1.1186e-05, -3.4027e-05, -1.8771e-05,\n",
      "        -8.5399e-05, -2.9664e-05,  4.3887e-05, -3.3708e-05,  1.2337e-05,\n",
      "        -1.7305e-05, -1.0994e-05,  4.0283e-05, -3.1075e-05, -3.3065e-05,\n",
      "         2.3224e-05,  6.9732e-05, -2.3917e-05, -7.0485e-06, -4.8739e-05,\n",
      "        -4.8367e-05, -4.6513e-05,  9.5028e-06,  7.1605e-05, -3.2466e-05,\n",
      "        -2.3564e-05,  6.5211e-06,  7.1398e-05, -5.6900e-05, -7.8780e-06,\n",
      "         4.5789e-05,  1.0477e-06,  1.0234e-05, -7.4009e-06, -7.2703e-05,\n",
      "         5.0016e-06, -3.1703e-05, -6.7291e-06, -3.4323e-05, -1.6635e-05,\n",
      "         3.3858e-05,  1.2206e-05, -7.7711e-05, -2.1465e-05, -1.5133e-05,\n",
      "        -7.0693e-05,  2.9119e-05,  1.4777e-05,  7.4580e-06,  6.5210e-05,\n",
      "         3.0188e-05,  1.0049e-05, -6.6026e-05,  1.3411e-05, -3.2327e-05,\n",
      "         1.2853e-06,  1.2868e-05, -4.9770e-05, -3.1308e-05,  4.8009e-07,\n",
      "        -4.4353e-06, -3.9918e-05,  7.9454e-05, -7.0381e-05,  6.3527e-05,\n",
      "        -6.8661e-06, -8.1445e-05, -5.3182e-06,  4.5796e-06,  8.0953e-06,\n",
      "        -4.5334e-05,  6.7932e-06,  4.8885e-06,  4.8274e-05,  1.2014e-05,\n",
      "         9.0100e-06,  2.3571e-06, -1.3293e-05,  3.1325e-05,  2.4920e-05,\n",
      "        -1.0770e-05, -2.3836e-05,  3.3066e-05,  7.1259e-05, -1.1420e-05,\n",
      "         1.0677e-05, -2.6379e-05, -1.8651e-05, -5.0178e-05, -9.2495e-05,\n",
      "        -2.3814e-05, -2.2266e-05,  9.6405e-06,  1.1763e-05, -5.1501e-06,\n",
      "        -1.2242e-06, -2.3275e-05,  1.4080e-05,  9.8706e-06, -7.6716e-05,\n",
      "        -3.6199e-05, -3.7948e-05, -7.7673e-05, -6.1800e-05,  4.3950e-05,\n",
      "        -2.6321e-05,  3.4365e-05,  1.2135e-05,  7.6005e-05, -1.5543e-05,\n",
      "        -2.6753e-05,  4.6065e-05, -1.8922e-06, -1.8281e-05,  2.3706e-05,\n",
      "        -7.6623e-05,  1.2584e-06,  1.8266e-05, -9.7140e-07,  8.0515e-05,\n",
      "        -1.1271e-05,  3.3216e-05,  4.5166e-06,  3.9877e-06, -3.0823e-05,\n",
      "         6.7316e-05,  2.5170e-06,  2.8841e-05, -1.9122e-05, -7.9747e-05,\n",
      "         1.0064e-05, -2.1744e-05,  1.6106e-05,  2.7413e-05,  6.9357e-05,\n",
      "        -6.9307e-05,  3.2930e-05,  3.7301e-05, -9.4462e-05, -1.1211e-05,\n",
      "        -1.8411e-05,  8.9644e-05,  1.7494e-05, -5.1402e-05,  6.3526e-06,\n",
      "         9.5171e-06, -9.0998e-05, -3.5767e-05,  6.7867e-05,  2.1927e-05,\n",
      "         5.6904e-06, -3.1180e-05,  5.3821e-05, -9.1338e-05,  6.3425e-05,\n",
      "         4.9085e-05, -5.1155e-05,  4.5661e-05, -8.7016e-05,  1.6932e-05,\n",
      "        -7.3895e-05,  1.5275e-05, -3.9799e-06,  3.6492e-05, -6.2813e-05,\n",
      "        -2.9428e-05, -6.5486e-05,  2.2903e-05,  1.4309e-05,  2.3520e-05,\n",
      "         6.5701e-06,  1.1066e-04,  1.9298e-05,  4.0032e-06,  1.7298e-05,\n",
      "        -1.2294e-05,  2.2265e-05,  3.5359e-05,  2.1671e-05, -5.1972e-05,\n",
      "        -3.0077e-05,  4.3682e-05,  3.9948e-05, -1.1707e-05, -1.4614e-05,\n",
      "        -4.9283e-06, -3.6385e-05, -5.6601e-05,  1.2553e-05,  1.0355e-05,\n",
      "         3.6278e-05, -6.4139e-06, -5.9473e-05, -4.2244e-05, -6.2393e-05,\n",
      "         4.5066e-05, -1.8089e-05,  1.1892e-05,  1.3240e-05,  1.9766e-05,\n",
      "         4.1996e-05, -3.8684e-05,  3.0284e-05,  6.1583e-05, -4.6994e-05,\n",
      "         9.4927e-06,  1.1102e-05, -2.8167e-05,  7.7780e-06,  2.1201e-05,\n",
      "         7.7356e-07, -7.0777e-05, -1.4063e-05,  4.1631e-05, -2.5569e-05,\n",
      "         4.1593e-05,  8.5702e-07, -1.5266e-05, -2.8721e-05, -4.1466e-05,\n",
      "         2.8957e-05, -1.8793e-05, -2.1275e-06,  4.1516e-05,  7.7786e-06,\n",
      "        -1.9995e-05,  2.0860e-05, -4.1316e-05,  8.5312e-05,  8.3689e-06,\n",
      "         6.5087e-05, -3.1254e-05,  3.3553e-05,  1.9579e-06,  2.3181e-05,\n",
      "         1.1448e-05,  2.8697e-05, -4.1532e-05,  8.8356e-06, -2.8937e-05,\n",
      "        -2.3149e-05,  2.5825e-05, -9.8347e-05,  4.0357e-05,  7.4915e-06,\n",
      "        -5.4518e-05, -6.5673e-05, -4.0789e-05,  1.3078e-07,  6.1538e-05,\n",
      "        -2.9910e-05, -3.5248e-05, -9.1504e-06, -4.5777e-05, -3.8979e-05,\n",
      "        -4.3033e-06, -1.2435e-05,  6.3566e-05,  3.9034e-05, -1.7706e-05,\n",
      "        -3.1508e-06,  6.5418e-05, -1.2221e-06,  5.2699e-05,  6.4202e-05,\n",
      "         2.3657e-05, -3.8451e-05,  2.8264e-05, -9.2659e-09,  5.5044e-05,\n",
      "        -1.6299e-05,  5.4009e-06, -6.6074e-05, -1.4773e-05,  1.9467e-05,\n",
      "         5.3381e-05,  2.5152e-06,  6.2344e-05, -7.3415e-05, -1.2246e-05,\n",
      "         3.1194e-05,  7.0277e-05,  3.2089e-05,  1.2957e-05,  7.3659e-06,\n",
      "        -4.9768e-06, -4.7932e-06, -5.6065e-06,  9.6702e-06, -4.4887e-05,\n",
      "        -3.1383e-05, -5.2688e-05,  1.3940e-05,  2.8818e-05, -5.4724e-05,\n",
      "         6.5389e-05,  4.5733e-06, -7.9076e-07, -4.1540e-05, -1.4784e-05,\n",
      "        -4.1104e-05,  1.9040e-05,  4.2134e-05, -6.5213e-05, -5.3641e-05,\n",
      "         2.6742e-06,  1.1277e-05,  2.8922e-05,  4.8354e-05,  1.1621e-05,\n",
      "        -1.3411e-05, -6.8503e-05, -4.3938e-05,  1.3139e-05,  2.9569e-05,\n",
      "         2.3381e-05,  3.7408e-05, -6.1413e-05,  7.3891e-06, -4.5033e-05,\n",
      "        -2.5624e-05, -4.9826e-06, -5.2207e-05, -1.4134e-05, -5.6740e-05,\n",
      "        -6.6177e-07, -3.5526e-05,  3.0880e-05, -7.8972e-05,  5.5345e-06,\n",
      "         3.7116e-05,  3.9451e-06,  5.3916e-05,  6.5338e-05,  5.6993e-05,\n",
      "         3.5549e-05,  6.5785e-05,  4.9674e-05,  6.3098e-05,  2.6540e-05,\n",
      "         7.2716e-05, -3.3740e-05, -4.8186e-05,  2.8300e-05, -6.9910e-06,\n",
      "         5.5134e-05,  4.6645e-05, -1.1019e-05, -6.0141e-05,  2.0936e-05,\n",
      "         2.7056e-05,  2.8424e-05, -2.1556e-05, -3.3959e-05,  2.1978e-05,\n",
      "         5.6863e-05,  1.8832e-05,  7.1250e-05,  2.4675e-05, -6.8952e-06,\n",
      "         6.2008e-05, -3.7917e-05, -5.1342e-05,  2.7768e-06, -9.1067e-05,\n",
      "         2.4664e-05,  3.6595e-05,  2.4553e-05, -2.0385e-05, -4.0671e-05,\n",
      "        -3.9622e-05,  8.4744e-05,  6.5233e-06, -4.8883e-06, -2.0109e-05,\n",
      "        -3.0323e-05, -5.8861e-06,  1.7504e-05,  2.1622e-05,  4.4647e-05,\n",
      "        -3.5981e-05, -1.6705e-05, -1.9370e-05,  1.4616e-05, -2.1175e-05,\n",
      "         2.7330e-05, -2.9551e-06,  8.0292e-05,  5.0090e-05,  1.9017e-05,\n",
      "         2.2440e-05,  1.7349e-05, -2.1225e-05, -5.6337e-05, -1.0617e-05,\n",
      "         1.6758e-05,  1.1465e-05,  3.1420e-05, -4.3789e-06, -1.0274e-05,\n",
      "         3.3094e-05, -4.9837e-06,  7.3493e-05, -4.1492e-05, -5.9365e-05,\n",
      "         2.7190e-05,  7.4680e-06,  2.1661e-05,  4.6593e-05,  1.8169e-05,\n",
      "        -4.1275e-05, -5.5599e-05, -8.5806e-06,  3.9909e-05,  1.6724e-05,\n",
      "         5.9379e-05, -1.3433e-05,  3.4425e-05,  3.8232e-05, -2.0014e-05,\n",
      "        -4.0412e-05, -3.2292e-05,  4.1481e-05, -5.0539e-05,  8.3743e-06,\n",
      "        -2.5316e-05, -5.8319e-05, -6.6307e-05,  5.2744e-05, -8.5533e-05,\n",
      "         5.1078e-05, -7.2073e-05,  1.6663e-05, -6.6541e-05, -4.6541e-05,\n",
      "         4.8048e-05,  3.5748e-05, -3.2991e-05,  4.8003e-05, -1.0778e-05,\n",
      "        -6.7572e-05,  6.1475e-05, -1.1375e-05, -7.8471e-05,  5.8886e-05,\n",
      "        -2.8128e-05, -9.1014e-06, -2.7531e-05,  4.5759e-05, -4.3559e-05,\n",
      "         5.2873e-05,  9.2122e-06,  1.4102e-05, -4.3509e-05, -5.0174e-05,\n",
      "         2.2075e-05,  2.2194e-05, -3.1492e-05, -1.3980e-06, -5.0633e-05,\n",
      "         5.0249e-05, -5.9968e-05, -4.9535e-05,  5.8693e-06, -2.7543e-05,\n",
      "        -3.2579e-05, -2.9891e-05,  6.9795e-05, -7.9146e-05,  4.1445e-05,\n",
      "         1.0250e-05,  5.0924e-06,  2.6989e-03,  4.4721e-03,  3.7533e-03,\n",
      "         4.5512e-03,  4.1502e-03,  2.9513e-03,  5.9549e-03,  5.3770e-03,\n",
      "         5.0768e-03,  2.8813e-03,  3.7819e-03,  3.2821e-03,  5.7367e-03,\n",
      "         3.9587e-03,  1.4935e-03,  2.9006e-03,  4.9122e-03,  3.4805e-03,\n",
      "         5.8450e-03,  5.1887e-03,  3.7568e-03,  3.8089e-03,  3.3516e-03,\n",
      "         3.8811e-03,  2.0398e-03,  3.0157e-03,  5.6585e-03,  4.9550e-03,\n",
      "         3.5805e-03,  3.9709e-03,  4.4970e-03,  2.8360e-03,  3.6634e-03,\n",
      "         3.8003e-03,  3.8613e-03,  3.0408e-03,  3.6016e-03,  5.1888e-03,\n",
      "         5.5515e-03,  4.7695e-03,  5.0574e-03,  4.0479e-03,  3.3136e-03,\n",
      "         4.2270e-03,  3.7414e-03,  3.6745e-03,  4.6714e-03,  4.0852e-03,\n",
      "         4.2270e-03,  4.4705e-03,  5.9616e-03,  4.3524e-03,  4.1869e-03,\n",
      "         4.2716e-03,  4.2209e-03,  3.6928e-03,  4.5437e-03,  3.3146e-03,\n",
      "         2.6463e-03,  3.8103e-03,  3.6178e-03,  3.3261e-03,  3.9091e-03,\n",
      "         2.8256e-03,  4.0885e-03,  3.6408e-03,  4.7933e-03,  4.2251e-03,\n",
      "         3.2577e-03,  4.7838e-03,  4.9889e-03,  1.8976e-03,  3.7522e-03,\n",
      "         2.9198e-03,  3.6055e-03,  4.6198e-03,  3.7620e-03,  3.3381e-03,\n",
      "         3.2757e-03,  3.1173e-03,  3.3551e-03,  3.4403e-03,  4.7822e-03,\n",
      "         2.9911e-03,  3.4032e-03,  4.3356e-03,  3.5560e-03,  2.2068e-03,\n",
      "         3.3176e-03,  4.4027e-03,  2.2750e-03,  3.7025e-03,  6.1129e-03,\n",
      "         2.2125e-03,  5.1111e-03,  2.3838e-03,  5.3839e-03,  4.5691e-03,\n",
      "         3.1113e-03,  2.9245e-03,  3.3848e-03,  4.1267e-03,  3.8284e-03,\n",
      "         4.9811e-03,  4.7159e-03,  3.8369e-03,  4.5476e-03,  3.0254e-03,\n",
      "         4.6469e-03,  4.2635e-03,  2.8529e-03,  2.7153e-03,  3.9945e-03,\n",
      "         3.5050e-03,  4.5246e-03,  3.0590e-03,  4.4502e-03,  2.5207e-03,\n",
      "         5.7726e-03,  3.4192e-03,  2.5903e-03,  2.5792e-03,  2.3673e-03,\n",
      "         4.9328e-03,  2.7485e-03,  4.1276e-03,  2.4506e-03,  2.9083e-03,\n",
      "         5.3651e-03,  4.4203e-03,  3.7095e-03,  2.5089e-03,  4.1591e-03,\n",
      "         3.0579e-03,  3.2091e-03,  4.3993e-03,  1.6525e-03,  3.9433e-03,\n",
      "         1.8985e-03,  5.2426e-03,  4.1632e-03,  4.6783e-03,  6.1941e-03,\n",
      "         4.0402e-03,  3.3197e-03,  3.4136e-03,  3.4978e-03,  2.2557e-03,\n",
      "         4.4248e-03,  4.2017e-03,  4.2083e-03,  5.2940e-03,  2.6001e-03,\n",
      "         3.6185e-03,  3.3549e-03,  4.2294e-03,  2.4537e-03,  3.5924e-03,\n",
      "         3.4658e-03,  4.4007e-03,  4.7920e-03,  4.3589e-03,  2.2327e-03,\n",
      "         3.3415e-03,  4.0071e-03,  4.6957e-03,  4.7435e-03,  3.1532e-03,\n",
      "         3.0063e-03,  5.3637e-03,  6.8273e-04,  4.6296e-03,  3.7842e-03,\n",
      "         2.9152e-03,  3.6508e-03,  4.7023e-03,  3.1507e-03,  4.9334e-03,\n",
      "         6.5421e-03,  3.0777e-03,  3.7300e-03,  6.4067e-03,  2.6168e-03,\n",
      "         3.3638e-03,  4.3550e-03,  2.8280e-03,  5.0984e-03,  2.7311e-03,\n",
      "         4.2922e-03,  3.8704e-03,  5.1576e-03,  3.3930e-03,  4.3790e-03,\n",
      "         4.7456e-03,  4.4295e-03,  2.8869e-03,  5.2162e-03,  3.8197e-03,\n",
      "         3.8011e-03,  3.6965e-03,  3.2406e-03,  3.9190e-03,  2.0354e-03,\n",
      "         3.1324e-03,  4.3814e-03,  3.8270e-03,  3.8249e-03,  2.7483e-03,\n",
      "         6.4247e-04,  4.0556e-03,  3.9824e-03,  4.7908e-03,  1.5482e-03,\n",
      "         5.0734e-03,  2.9036e-03,  1.9500e-03,  2.3396e-03,  1.9706e-03,\n",
      "         3.3550e-03,  3.5632e-03,  4.1536e-03,  3.2495e-03,  3.4793e-03,\n",
      "         4.7598e-03,  3.7276e-03,  3.3417e-03,  3.9955e-03,  3.6662e-03,\n",
      "         4.2332e-03,  1.7574e-03,  4.4126e-03,  2.9003e-03,  5.0885e-03,\n",
      "         4.5909e-03,  4.4599e-03,  4.6307e-03,  4.8934e-03,  4.9217e-03,\n",
      "         2.6435e-03,  2.8974e-03,  3.3164e-03,  3.1746e-03,  5.0404e-03,\n",
      "         4.0932e-03,  5.2279e-03,  3.6365e-03,  3.6744e-03,  2.6969e-03,\n",
      "         3.5214e-03,  2.8397e-03,  2.9119e-03,  3.4815e-03,  3.3146e-03,\n",
      "         3.4736e-03,  5.0963e-03,  3.7815e-03])\n",
      "tensor([-4.7002e-06,  1.6295e-05, -3.7418e-05, -4.1267e-05,  5.6760e-05,\n",
      "         8.5028e-06, -6.0175e-05, -4.8426e-05, -3.1590e-05,  4.8215e-05,\n",
      "         6.1081e-05, -4.5411e-05,  7.4177e-06, -1.4473e-05,  6.0757e-06,\n",
      "        -3.8177e-05, -5.3071e-05,  2.1001e-05, -5.5036e-05, -4.4694e-05,\n",
      "         2.4267e-05,  6.5968e-05, -4.7590e-05, -2.5787e-05, -2.4033e-06,\n",
      "         4.3265e-05,  3.4744e-05, -5.8699e-07, -2.9379e-05,  1.2996e-05,\n",
      "         1.6895e-05,  7.3424e-06,  5.2332e-05, -2.9058e-05, -1.3331e-05,\n",
      "         2.5030e-05,  4.6784e-05, -1.2505e-05, -4.3530e-05, -7.1356e-05,\n",
      "         4.8852e-06, -6.4670e-05, -1.1186e-05, -3.4027e-05, -1.8771e-05,\n",
      "        -8.5399e-05, -2.9664e-05,  4.3887e-05, -3.3708e-05,  1.2337e-05,\n",
      "        -1.7305e-05, -1.0994e-05,  4.0283e-05, -3.1075e-05, -3.3065e-05,\n",
      "         2.3224e-05,  6.9732e-05, -2.3917e-05, -7.0485e-06, -4.8739e-05,\n",
      "        -4.8367e-05, -4.6513e-05,  9.5028e-06,  7.1605e-05, -3.2466e-05,\n",
      "        -2.3564e-05,  6.5211e-06,  7.1398e-05, -5.6900e-05, -7.8780e-06,\n",
      "         4.5789e-05,  1.0477e-06,  1.0234e-05, -7.4009e-06, -7.2703e-05,\n",
      "         5.0016e-06, -3.1703e-05, -6.7291e-06, -3.4323e-05, -1.6635e-05,\n",
      "         3.3858e-05,  1.2206e-05, -7.7711e-05, -2.1465e-05, -1.5133e-05,\n",
      "        -7.0693e-05,  2.9119e-05,  1.4777e-05,  7.4580e-06,  6.5210e-05,\n",
      "         3.0188e-05,  1.0049e-05, -6.6026e-05,  1.3411e-05, -3.2327e-05,\n",
      "         1.2853e-06,  1.2868e-05, -4.9770e-05, -3.1308e-05,  4.8009e-07,\n",
      "        -4.4353e-06, -3.9918e-05,  7.9454e-05, -7.0381e-05,  6.3527e-05,\n",
      "        -6.8661e-06, -8.1445e-05, -5.3182e-06,  4.5796e-06,  8.0953e-06,\n",
      "        -4.5334e-05,  6.7932e-06,  4.8885e-06,  4.8274e-05,  1.2014e-05,\n",
      "         9.0100e-06,  2.3571e-06, -1.3293e-05,  3.1325e-05,  2.4920e-05,\n",
      "        -1.0770e-05, -2.3836e-05,  3.3066e-05,  7.1259e-05, -1.1420e-05,\n",
      "         1.0677e-05, -2.6379e-05, -1.8651e-05, -5.0178e-05, -9.2495e-05,\n",
      "        -2.3814e-05, -2.2266e-05,  9.6405e-06,  1.1763e-05, -5.1501e-06,\n",
      "        -1.2242e-06, -2.3275e-05,  1.4080e-05,  9.8706e-06, -7.6716e-05,\n",
      "        -3.6199e-05, -3.7948e-05, -7.7673e-05, -6.1800e-05,  4.3950e-05,\n",
      "        -2.6321e-05,  3.4365e-05,  1.2135e-05,  7.6005e-05, -1.5543e-05,\n",
      "        -2.6753e-05,  4.6065e-05, -1.8922e-06, -1.8281e-05,  2.3706e-05,\n",
      "        -7.6623e-05,  1.2584e-06,  1.8266e-05, -9.7140e-07,  8.0515e-05,\n",
      "        -1.1271e-05,  3.3216e-05,  4.5166e-06,  3.9877e-06, -3.0823e-05,\n",
      "         6.7316e-05,  2.5170e-06,  2.8841e-05, -1.9122e-05, -7.9747e-05,\n",
      "         1.0064e-05, -2.1744e-05,  1.6106e-05,  2.7413e-05,  6.9357e-05,\n",
      "        -6.9307e-05,  3.2930e-05,  3.7301e-05, -9.4462e-05, -1.1211e-05,\n",
      "        -1.8411e-05,  8.9644e-05,  1.7494e-05, -5.1402e-05,  6.3526e-06,\n",
      "         9.5171e-06, -9.0998e-05, -3.5767e-05,  6.7867e-05,  2.1927e-05,\n",
      "         5.6904e-06, -3.1180e-05,  5.3821e-05, -9.1338e-05,  6.3425e-05,\n",
      "         4.9085e-05, -5.1155e-05,  4.5661e-05, -8.7016e-05,  1.6932e-05,\n",
      "        -7.3895e-05,  1.5275e-05, -3.9799e-06,  3.6492e-05, -6.2813e-05,\n",
      "        -2.9428e-05, -6.5486e-05,  2.2903e-05,  1.4309e-05,  2.3520e-05,\n",
      "         6.5701e-06,  1.1066e-04,  1.9298e-05,  4.0032e-06,  1.7298e-05,\n",
      "        -1.2294e-05,  2.2265e-05,  3.5359e-05,  2.1671e-05, -5.1972e-05,\n",
      "        -3.0077e-05,  4.3682e-05,  3.9948e-05, -1.1707e-05, -1.4614e-05,\n",
      "        -4.9283e-06, -3.6385e-05, -5.6601e-05,  1.2553e-05,  1.0355e-05,\n",
      "         3.6278e-05, -6.4139e-06, -5.9473e-05, -4.2244e-05, -6.2393e-05,\n",
      "         4.5066e-05, -1.8089e-05,  1.1892e-05,  1.3240e-05,  1.9766e-05,\n",
      "         4.1996e-05, -3.8684e-05,  3.0284e-05,  6.1583e-05, -4.6994e-05,\n",
      "         9.4927e-06,  1.1101e-05, -2.8167e-05,  7.7780e-06,  2.1201e-05,\n",
      "         7.7356e-07, -7.0777e-05, -1.4063e-05,  4.1631e-05, -2.5569e-05,\n",
      "         4.1593e-05,  8.5702e-07, -1.5266e-05, -2.8721e-05, -4.1466e-05,\n",
      "         2.8957e-05, -1.8793e-05, -2.1275e-06,  4.1516e-05,  7.7786e-06,\n",
      "        -1.9995e-05,  2.0860e-05, -4.1316e-05,  8.5312e-05,  8.3689e-06,\n",
      "         6.5087e-05, -3.1254e-05,  3.3553e-05,  1.9579e-06,  2.3181e-05,\n",
      "         1.1448e-05,  2.8697e-05, -4.1532e-05,  8.8356e-06, -2.8937e-05,\n",
      "        -2.3149e-05,  2.5825e-05, -9.8347e-05,  4.0357e-05,  7.4915e-06,\n",
      "        -5.4518e-05, -6.5673e-05, -4.0789e-05,  1.3078e-07,  6.1538e-05,\n",
      "        -2.9910e-05, -3.5248e-05, -9.1504e-06, -4.5777e-05, -3.8979e-05,\n",
      "        -4.3033e-06, -1.2435e-05,  6.3566e-05,  3.9034e-05, -1.7706e-05,\n",
      "        -3.1508e-06,  6.5418e-05, -1.2221e-06,  5.2699e-05,  6.4202e-05,\n",
      "         2.3657e-05, -3.8451e-05,  2.8264e-05, -9.2668e-09,  5.5044e-05,\n",
      "        -1.6299e-05,  5.4009e-06, -6.6074e-05, -1.4773e-05,  1.9467e-05,\n",
      "         5.3381e-05,  2.5152e-06,  6.2344e-05, -7.3415e-05, -1.2246e-05,\n",
      "         3.1194e-05,  7.0277e-05,  3.2089e-05,  1.2957e-05,  7.3659e-06,\n",
      "        -4.9768e-06, -4.7932e-06, -5.6065e-06,  9.6702e-06, -4.4887e-05,\n",
      "        -3.1383e-05, -5.2688e-05,  1.3940e-05,  2.8818e-05, -5.4724e-05,\n",
      "         6.5389e-05,  4.5733e-06, -7.9077e-07, -4.1540e-05, -1.4784e-05,\n",
      "        -4.1104e-05,  1.9040e-05,  4.2134e-05, -6.5213e-05, -5.3641e-05,\n",
      "         2.6742e-06,  1.1277e-05,  2.8922e-05,  4.8354e-05,  1.1621e-05,\n",
      "        -1.3411e-05, -6.8503e-05, -4.3938e-05,  1.3139e-05,  2.9569e-05,\n",
      "         2.3381e-05,  3.7408e-05, -6.1413e-05,  7.3891e-06, -4.5033e-05,\n",
      "        -2.5624e-05, -4.9826e-06, -5.2207e-05, -1.4134e-05, -5.6740e-05,\n",
      "        -6.6177e-07, -3.5526e-05,  3.0880e-05, -7.8972e-05,  5.5345e-06,\n",
      "         3.7116e-05,  3.9451e-06,  5.3916e-05,  6.5338e-05,  5.6993e-05,\n",
      "         3.5550e-05,  6.5785e-05,  4.9674e-05,  6.3098e-05,  2.6540e-05,\n",
      "         7.2716e-05, -3.3740e-05, -4.8186e-05,  2.8300e-05, -6.9910e-06,\n",
      "         5.5134e-05,  4.6645e-05, -1.1019e-05, -6.0141e-05,  2.0936e-05,\n",
      "         2.7056e-05,  2.8424e-05, -2.1556e-05, -3.3959e-05,  2.1978e-05,\n",
      "         5.6863e-05,  1.8832e-05,  7.1250e-05,  2.4675e-05, -6.8952e-06,\n",
      "         6.2008e-05, -3.7917e-05, -5.1342e-05,  2.7768e-06, -9.1067e-05,\n",
      "         2.4664e-05,  3.6595e-05,  2.4553e-05, -2.0385e-05, -4.0671e-05,\n",
      "        -3.9622e-05,  8.4744e-05,  6.5233e-06, -4.8883e-06, -2.0109e-05,\n",
      "        -3.0323e-05, -5.8861e-06,  1.7504e-05,  2.1622e-05,  4.4647e-05,\n",
      "        -3.5981e-05, -1.6705e-05, -1.9370e-05,  1.4616e-05, -2.1175e-05,\n",
      "         2.7330e-05, -2.9551e-06,  8.0292e-05,  5.0090e-05,  1.9017e-05,\n",
      "         2.2440e-05,  1.7349e-05, -2.1225e-05, -5.6337e-05, -1.0617e-05,\n",
      "         1.6758e-05,  1.1465e-05,  3.1420e-05, -4.3789e-06, -1.0274e-05,\n",
      "         3.3094e-05, -4.9837e-06,  7.3493e-05, -4.1492e-05, -5.9365e-05,\n",
      "         2.7190e-05,  7.4680e-06,  2.1661e-05,  4.6593e-05,  1.8169e-05,\n",
      "        -4.1275e-05, -5.5599e-05, -8.5806e-06,  3.9909e-05,  1.6724e-05,\n",
      "         5.9379e-05, -1.3433e-05,  3.4425e-05,  3.8232e-05, -2.0014e-05,\n",
      "        -4.0412e-05, -3.2292e-05,  4.1482e-05, -5.0539e-05,  8.3743e-06,\n",
      "        -2.5316e-05, -5.8319e-05, -6.6307e-05,  5.2744e-05, -8.5533e-05,\n",
      "         5.1078e-05, -7.2073e-05,  1.6663e-05, -6.6541e-05, -4.6541e-05,\n",
      "         4.8048e-05,  3.5748e-05, -3.2991e-05,  4.8003e-05, -1.0778e-05,\n",
      "        -6.7572e-05,  6.1475e-05, -1.1375e-05, -7.8471e-05,  5.8886e-05,\n",
      "        -2.8128e-05, -9.1014e-06, -2.7531e-05,  4.5759e-05, -4.3559e-05,\n",
      "         5.2873e-05,  9.2122e-06,  1.4102e-05, -4.3509e-05, -5.0174e-05,\n",
      "         2.2075e-05,  2.2194e-05, -3.1492e-05, -1.3980e-06, -5.0633e-05,\n",
      "         5.0249e-05, -5.9968e-05, -4.9535e-05,  5.8693e-06, -2.7543e-05,\n",
      "        -3.2579e-05, -2.9891e-05,  6.9795e-05, -7.9146e-05,  4.1445e-05,\n",
      "         1.0250e-05,  5.0924e-06,  1.3166e-03,  2.1352e-03,  1.8328e-03,\n",
      "         2.2571e-03,  1.9783e-03,  1.5466e-03,  3.0156e-03,  2.6875e-03,\n",
      "         2.3689e-03,  1.4005e-03,  1.8533e-03,  1.5666e-03,  2.8932e-03,\n",
      "         1.9813e-03,  7.7376e-04,  1.3375e-03,  2.5377e-03,  1.6695e-03,\n",
      "         2.9231e-03,  2.5598e-03,  1.8096e-03,  1.9625e-03,  1.7463e-03,\n",
      "         2.0572e-03,  1.0606e-03,  1.5315e-03,  2.9161e-03,  2.5406e-03,\n",
      "         1.7577e-03,  2.0253e-03,  2.2518e-03,  1.4135e-03,  1.8726e-03,\n",
      "         1.9310e-03,  2.0027e-03,  1.4556e-03,  1.7772e-03,  2.6770e-03,\n",
      "         2.7545e-03,  2.3626e-03,  2.5314e-03,  1.9152e-03,  1.6724e-03,\n",
      "         2.1156e-03,  1.8111e-03,  1.9093e-03,  2.2232e-03,  2.1156e-03,\n",
      "         2.1710e-03,  2.0520e-03,  2.9060e-03,  2.2208e-03,  2.0785e-03,\n",
      "         2.1199e-03,  2.1243e-03,  1.7569e-03,  2.3326e-03,  1.6816e-03,\n",
      "         1.3323e-03,  1.8987e-03,  1.8799e-03,  1.6954e-03,  1.9321e-03,\n",
      "         1.3853e-03,  2.0253e-03,  1.8502e-03,  2.3245e-03,  2.0521e-03,\n",
      "         1.5522e-03,  2.3537e-03,  2.4521e-03,  9.5347e-04,  1.8567e-03,\n",
      "         1.5517e-03,  1.7983e-03,  2.3352e-03,  1.8532e-03,  1.6839e-03,\n",
      "         1.5814e-03,  1.6315e-03,  1.6820e-03,  1.5917e-03,  2.4322e-03,\n",
      "         1.3901e-03,  1.7723e-03,  2.1526e-03,  1.8080e-03,  1.1373e-03,\n",
      "         1.5917e-03,  2.1110e-03,  1.1519e-03,  1.8440e-03,  3.1316e-03,\n",
      "         1.1370e-03,  2.5436e-03,  1.1600e-03,  2.6137e-03,  2.3013e-03,\n",
      "         1.5694e-03,  1.4613e-03,  1.6206e-03,  1.9621e-03,  2.0608e-03,\n",
      "         2.6182e-03,  2.4019e-03,  1.9537e-03,  2.2577e-03,  1.4814e-03,\n",
      "         2.2975e-03,  2.0645e-03,  1.3775e-03,  1.3769e-03,  1.9635e-03,\n",
      "         1.6937e-03,  2.2740e-03,  1.5349e-03,  2.1560e-03,  1.2309e-03,\n",
      "         2.9066e-03,  1.6443e-03,  1.2975e-03,  1.2545e-03,  1.1232e-03,\n",
      "         2.3798e-03,  1.3836e-03,  2.0253e-03,  1.2141e-03,  1.4718e-03,\n",
      "         2.6640e-03,  2.3214e-03,  1.8505e-03,  1.2801e-03,  2.0803e-03,\n",
      "         1.4974e-03,  1.5481e-03,  2.2327e-03,  8.3867e-04,  1.9295e-03,\n",
      "         9.4691e-04,  2.6340e-03,  2.0230e-03,  2.4001e-03,  3.3001e-03,\n",
      "         2.0145e-03,  1.6813e-03,  1.7223e-03,  1.7124e-03,  1.1767e-03,\n",
      "         2.3015e-03,  2.1607e-03,  2.0973e-03,  2.7213e-03,  1.2649e-03,\n",
      "         1.8427e-03,  1.7930e-03,  2.2573e-03,  1.2256e-03,  1.7364e-03,\n",
      "         1.7469e-03,  2.1446e-03,  2.3976e-03,  2.1461e-03,  1.1842e-03,\n",
      "         1.7107e-03,  1.9749e-03,  2.4517e-03,  2.2209e-03,  1.6203e-03,\n",
      "         1.4942e-03,  2.6763e-03,  3.1929e-04,  2.4272e-03,  1.9126e-03,\n",
      "         1.4767e-03,  1.7759e-03,  2.4132e-03,  1.5407e-03,  2.5134e-03,\n",
      "         3.2051e-03,  1.5005e-03,  1.8558e-03,  3.1627e-03,  1.4299e-03,\n",
      "         1.6877e-03,  2.2537e-03,  1.3623e-03,  2.4962e-03,  1.3401e-03,\n",
      "         2.0427e-03,  1.9791e-03,  2.4858e-03,  1.7886e-03,  2.1659e-03,\n",
      "         2.4164e-03,  2.1423e-03,  1.5133e-03,  2.6248e-03,  1.8451e-03,\n",
      "         1.8627e-03,  1.8436e-03,  1.6801e-03,  1.9673e-03,  1.0040e-03,\n",
      "         1.6499e-03,  2.0994e-03,  1.9141e-03,  1.9843e-03,  1.2741e-03,\n",
      "         3.5249e-04,  1.9861e-03,  1.9448e-03,  2.4460e-03,  7.6129e-04,\n",
      "         2.5675e-03,  1.3935e-03,  9.0029e-04,  1.2278e-03,  9.4524e-04,\n",
      "         1.6559e-03,  1.7720e-03,  2.0809e-03,  1.6027e-03,  1.7359e-03,\n",
      "         2.3198e-03,  1.7536e-03,  1.6149e-03,  1.9725e-03,  1.8587e-03,\n",
      "         2.1048e-03,  9.3409e-04,  2.1996e-03,  1.4581e-03,  2.5354e-03,\n",
      "         2.1727e-03,  2.2361e-03,  2.4064e-03,  2.4137e-03,  2.5797e-03,\n",
      "         1.2936e-03,  1.4660e-03,  1.5995e-03,  1.5285e-03,  2.5777e-03,\n",
      "         1.9146e-03,  2.6311e-03,  1.9098e-03,  1.7837e-03,  1.4378e-03,\n",
      "         1.7918e-03,  1.4287e-03,  1.4272e-03,  1.7563e-03,  1.6220e-03,\n",
      "         1.7847e-03,  2.5542e-03,  1.9128e-03])\n"
     ]
    }
   ],
   "source": [
    "for param in gru.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2c4e37f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 6.)\n",
    "k, i = x.topk(1)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a5609f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33305008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
