{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632e923e",
   "metadata": {},
   "source": [
    "# Communication policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc7466",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4929b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_pairs(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    pairs = []\n",
    "    for step, s_data in data.items():\n",
    "        if not step.startswith(\"Step\"):\n",
    "            continue\n",
    "        pairs.append({\n",
    "            \"observation\": s_data[\"Agent_0\"][\"Observation\"],\n",
    "            \"sentence\": s_data[\"Agent_0\"][\"Sentence\"][1:-1]\n",
    "        })\n",
    "        pairs.append({\n",
    "            \"observation\": s_data[\"Agent_1\"][\"Observation\"],\n",
    "            \"sentence\": s_data[\"Agent_1\"][\"Sentence\"][1:-1]\n",
    "        })\n",
    "    return pairs\n",
    "\n",
    "data_pairs = load_pairs(\"test_data/Sentences_Generated_P1.json\")\n",
    "\n",
    "train_data = data_pairs[:80000]\n",
    "test_data = data_pairs[80000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79cce954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5278,  0.2009, -0.1439, -0.1794, -0.6431,  0.0351, -0.1024, -0.1001,\n",
      "          0.6527,  0.6745,  0.0047, -0.3461, -0.2081, -0.3148,  0.1714, -0.3583,\n",
      "          0.6270, -0.7164, -0.2638, -0.5845,  0.3001,  0.4664,  0.1918, -0.1113,\n",
      "         -0.2141,  0.3801,  0.2028,  0.0408,  0.8720, -0.1324, -0.6387, -0.2342]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[[ 0.1246, -0.0066,  0.0979, -0.1150,  0.1686, -0.0200, -0.1921,\n",
      "          -0.0318,  0.1319, -0.0009,  0.2391,  0.1782,  0.1255, -0.0446,\n",
      "          -0.1537, -0.0456,  0.1508,  0.1353, -0.0618,  0.2609,  0.0446,\n",
      "          -0.1089, -0.0155, -0.1736, -0.2275,  0.0869, -0.1603,  0.0746,\n",
      "          -0.1047, -0.2703,  0.0377,  0.2223]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from model.modules.obs import ObservationEncoder\n",
    "from model.modules.lm import GRUEncoder, GRUDecoder, OneHotEncoder\n",
    "from model.modules.comm import CommunicationPolicy\n",
    "\n",
    "cp = CommunicationPolicy(32, 32)\n",
    "\n",
    "word_encoder = OneHotEncoder(['South','Not','Located','West','Object','Landmark','North','Center','East'])\n",
    "lang_enc = GRUEncoder(32, word_encoder)\n",
    "obs_enc = ObservationEncoder(17, 32)\n",
    "dec = GRUDecoder(32, word_encoder)\n",
    "\n",
    "obs = torch.Tensor([train_data[0][\"observation\"]])\n",
    "sent = [train_data[0][\"sentence\"]]\n",
    "\n",
    "int_context = obs_enc(obs)\n",
    "ext_context = lang_enc(sent)\n",
    "print(int_context)\n",
    "print(ext_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1baaf17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5278,  0.2009, -0.1439, -0.1794, -0.6431,  0.0351, -0.1024,\n",
      "          -0.1001,  0.6527,  0.6745,  0.0047, -0.3461, -0.2081, -0.3148,\n",
      "           0.1714, -0.3583,  0.6270, -0.7164, -0.2638, -0.5845,  0.3001,\n",
      "           0.4664,  0.1918, -0.1113, -0.2141,  0.3801,  0.2028,  0.0408,\n",
      "           0.8720, -0.1324, -0.6387, -0.2342,  0.1246, -0.0066,  0.0979,\n",
      "          -0.1150,  0.1686, -0.0200, -0.1921, -0.0318,  0.1319, -0.0009,\n",
      "           0.2391,  0.1782,  0.1255, -0.0446, -0.1537, -0.0456,  0.1508,\n",
      "           0.1353, -0.0618,  0.2609,  0.0446, -0.1089, -0.0155, -0.1736,\n",
      "          -0.2275,  0.0869, -0.1603,  0.0746, -0.1047, -0.2703,  0.0377,\n",
      "           0.2223]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.2708,  0.1085,  0.0503,  0.3166, -0.0694,  0.0567, -0.0667,\n",
      "          -0.1321, -0.1112,  0.1799,  0.1097,  0.0664,  0.0462, -0.0452,\n",
      "          -0.0383, -0.1069, -0.0066, -0.1147, -0.2578, -0.1731, -0.1166,\n",
      "           0.3007,  0.1309, -0.0035,  0.1634,  0.0251, -0.0161, -0.2419,\n",
      "          -0.0603,  0.0175,  0.0319, -0.1147]]], grad_fn=<TransposeBackward1>) torch.Size([1, 1, 32])\n"
     ]
    }
   ],
   "source": [
    "output, hidden = cp(int_context, ext_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b39537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0460,  0.0168,  0.0324,  0.0726, -0.1170, -0.0970, -0.0134, -0.1694,\n",
       "          0.0113,  0.1130,  0.0469,  0.0866,  0.0182, -0.1436,  0.0485,  0.0856,\n",
       "         -0.2451,  0.0567,  0.0902, -0.1024, -0.0987, -0.1128,  0.0418, -0.1827,\n",
       "          0.1020,  0.2304,  0.1658,  0.0539, -0.2380, -0.1792, -0.0792, -0.1636]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349153aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
